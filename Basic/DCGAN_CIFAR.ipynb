{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTFyo8ctOZnZl/7XHYDqNJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def make_D(in_shape = (32,32,3)):\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3,3), padding = 'same', input_shape = in_shape),\n",
        "        LeakyReLU(alpha = 0.2),\n",
        "        Conv2D(128, (3,3), strides = (2,2), padding = 'same'),\n",
        "        LeakyReLU(alpha = 0.2),\n",
        "        Conv2D(128, (3,3), strides = (2,2), padding = 'same'),\n",
        "        LeakyReLU(alpha = 0.2),\n",
        "        Conv2D(256, (3,3), strides = (2,2), padding = 'same'),\n",
        "        LeakyReLU(alpha = 0.2),\n",
        "        Flatten(),\n",
        "        Dropout(0.4),\n",
        "        Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "    opt = Adam(learning_rate = 0.0002, beta_1 = 0.5)\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "5gVng0d4T-f6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.utils import plot_model\n",
        "\n",
        "def make_G(latent_dims):\n",
        "    model = Sequential([\n",
        "        Dense(256*4*4, input_dim = latent_dims),\n",
        "        LeakyReLU(alpha = 0.2),\n",
        "        Reshape((4, 4, 256)),\n",
        "        Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'),\n",
        "        LeakyReLU(alpha = 0.2),\n",
        "        Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'),\n",
        "        LeakyReLU(alpha = 0.2),\n",
        "        Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'),\n",
        "        LeakyReLU(alpha = 0.2),\n",
        "        Conv2D(3, (3,3), activation = 'tanh', padding = 'same')\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "fePlJYBcW7lj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "def make_GAN(G, D):\n",
        "    GAN = Sequential()\n",
        "\n",
        "    D.trainable = False\n",
        "\n",
        "    GAN.add(G)\n",
        "    GAN.add(D)\n",
        "\n",
        "    opt = Adam(learning_rate = 0.0002, beta_1 = 0.5)\n",
        "\n",
        "    GAN.compile(loss = 'binary_crossentropy', optimizer = opt)\n",
        "\n",
        "    return GAN\n"
      ],
      "metadata": {
        "id": "ZnXfUNDz9ce0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def save_plot(samples, epoch, n = 5):\n",
        "    for i in range(n*n):\n",
        "        plt.subplot(n, n, i+1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(samples[i])\n",
        "    filename = f'gen_plot_{epoch+1}'\n",
        "    plt.savefig(filename)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "m8KSdjMI18qF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def view_performance(epoch, dataset, G, D, latent_dim, n_samples = 150):\n",
        "\n",
        "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\n",
        "    _, acc_real = D.evaluate(X_real, y_real, verbose = 0)\n",
        "\n",
        "    X_fake, y_fake = generate_fake_samples(G, n_samples, latent_dim)\n",
        "\n",
        "    _, acc_fake = D.evaluate(X_fake, y_fake, verbose = 0)\n",
        "\n",
        "    print(f'Acc real : {acc_real} - Acc_fake : {acc_fake}')\n",
        "\n",
        "    save_plot(X_fake, epoch)\n",
        "\n",
        "    filename = f'gen_model{epoch+1}.h5'\n",
        "    G.save(filename)\n"
      ],
      "metadata": {
        "id": "OyGFVSTGzfSC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets.cifar10 import load_data\n",
        "\n",
        "def load_real_samples():\n",
        "    (Xt, _), (_, _) = load_data()\n",
        "\n",
        "    X = Xt.astype('float32')\n",
        "\n",
        "    X = (X - 127.5) / 127.5\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "n9d-4OHodXlS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import randint\n",
        "from numpy import ones\n",
        "\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\n",
        "    i = randint(0, dataset.shape[0], n_samples)\n",
        "\n",
        "    X = dataset[i]\n",
        "\n",
        "    y = ones((n_samples, 1))\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "CpyyUMRee6ob"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import randn\n",
        "\n",
        "def generate_latent_points(n_samples, latent_dims):\n",
        "    x = randn(n_samples * latent_dims)\n",
        "    x = x.reshape(n_samples, latent_dims)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "G5CTn0TGgfsO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import rand\n",
        "from numpy import zeros\n",
        "\n",
        "def generate_fake_samples(G, n_samples, latent_dim):\n",
        "\n",
        "    l = generate_latent_points(n_samples, latent_dim)\n",
        "    X = G.predict(l, verbose = 0)\n",
        "    y = zeros((n_samples, 1))\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "H0_Dom8w3q92"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_GAN(G, D, GAN, dataset, latent_dim, epochs = 200, batch_size = 128):\n",
        "    batch_p_epoch = dataset.shape[0] // batch_size\n",
        "    half_batch = batch_size // 2\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for batch in range(batch_p_epoch):\n",
        "\n",
        "            x_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\n",
        "            D_lossR, _ = D.train_on_batch(x_real, y_real)\n",
        "\n",
        "            x_fake, y_fake = generate_fake_samples(G, half_batch, latent_dim)\n",
        "\n",
        "            D_lossF, _ = D.train_on_batch(x_fake, y_fake)\n",
        "\n",
        "            x_gan = generate_latent_points(batch_size, latent_dim)\n",
        "\n",
        "            y_gan = ones((batch_size, 1))\n",
        "\n",
        "            G_loss = GAN.train_on_batch(x_gan, y_gan)\n",
        "\n",
        "            print(f'{epoch+1}/{epochs} - {batch+1}/{batch_p_epoch} - D_lossR : {D_lossR} - D_lossF : {D_lossF} - G_loss : {G_loss}')\n",
        "\n",
        "            # check accuracy after every for every 10 epochs\n",
        "            if (epoch+1) % 10 == 0 :\n",
        "                view_performance(epoch, dataset, G, D, latent_dim)\n"
      ],
      "metadata": {
        "id": "0ejStBnAWoJC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_dim = 100\n",
        "\n",
        "Dis = make_D()\n",
        "\n",
        "Gen = make_G(L_dim)\n",
        "\n",
        "gan = make_GAN(Gen, Dis)\n",
        "\n",
        "cifar = load_real_samples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnRfASGmNkYT",
        "outputId": "e8020e29-72d9-4f73-d06c-4e53c8e7e9a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 12s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_GAN(Gen, Dis, gan, cifar, L_dim)"
      ],
      "metadata": {
        "id": "yW1JWfbDYKck"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqXKV5kmsdY+cb6xgFFQrw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam\n",
        "from numpy import load"
      ],
      "metadata": {
        "id": "S-N0HazIqUR_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q99klPpTgoUz"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "after having understood how we prepare the celeb10 data for the GAN\n",
        "(check CelebA - Preparing the data)\n",
        "we now implement it,\n",
        "\n",
        "we'll first define the D\n",
        "\n",
        "it'll take an input of (80,80,3) - image's pixel data array\n",
        "\n",
        "over 5 conv + leakyrelu layers we'll get\n",
        "\n",
        "80 -> 40 -> 20 -> 10 -> 5\n",
        "\n",
        "then we'll add 1 more similar layer and pass the output to a flatten + dropout + dense\n",
        "\n",
        "add to it adam and compile\n",
        "'''\n",
        "\n",
        "def make_D(in_shape = (80, 80, 3)):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(128, (5,5), padding = 'same', input_shape = in_shape))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (5,5), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (5,5), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (5,5), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (5,5), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    opt = Adam(learning_rate = 0.0002, beta_1 = 0.5)\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = opt, meter = ['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "and now the generator\n",
        "'''\n",
        "\n",
        "def define_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "\n",
        "    n_nodes = 128 * 5 * 5\n",
        "\n",
        "    model.add(Dense(n_nodes, input_dim = latent_dim))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Reshape((5, 5, 128)))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Conv2D(3, (5,5), activation = 'tanh', padding = 'same'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "3fgRzHJpk2QI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_GAN(gen, dis):\n",
        "    dis.trainable = False\n",
        "\n",
        "    gan = Sequential()\n",
        "\n",
        "    gan.add(gen)\n",
        "    gan.add(dis)\n",
        "\n",
        "    opt = Adam(learning_rate = 0.0002, beta_1 = 0.5)\n",
        "\n",
        "    gan.compile(loss = 'binary_crossentropy', optimizer = opt)\n",
        "\n",
        "    return gan"
      ],
      "metadata": {
        "id": "pJLzNRjYrnuy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_real_samples():\n",
        "    data = load('data.npz')\n",
        "    X = data['arr_0']\n",
        "\n",
        "    X = X.astype('float32')\n",
        "\n",
        "    X = (X - 127.5) / 127.5\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "FrgkdEg8vFOy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import randint\n",
        "from numpy import ones\n",
        "\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "    i = randint(0, dataset.shape[0], n_samples)\n",
        "\n",
        "    X = dataset[i]\n",
        "\n",
        "    y = ones((n_samples, 1))\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "Z6pSuazCzPcD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import randn\n",
        "\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    X = randn(latent_dim * n_samples)\n",
        "\n",
        "    X = X.reshape(n_samples, latent_dim)\n",
        "    return X"
      ],
      "metadata": {
        "id": "L_GLHw_7J43J"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import zeros\n",
        "\n",
        "def generate_fake_samples(gen, latent_dim, n_samples):\n",
        "    X = generate_latent_points(latent_dim, n_samples)\n",
        "\n",
        "    X_in = gen.predict(X, verbose = 'off')\n",
        "\n",
        "    y = zeros((n_samples, 1))\n",
        "    return X_in, y"
      ],
      "metadata": {
        "id": "O0bSOO8AXEQj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(gan, gen, dis, dataset, latent_dim, n_epochs = 20, batch_size = 128):\n",
        "    batch_p_epoch = dataset.shape[0] // batch_size\n",
        "    half_batch = batch_size // 2\n",
        "\n",
        "    for i in range(n_epochs):\n",
        "        for j in range(batch_p_epoch):\n",
        "\n",
        "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\n",
        "            d_lossR, _ = dis.train_on_batch(X_real, y_real)\n",
        "\n",
        "            X_fake, y_fake = generate_fake_samples(gen, latent_dim, half_batch)\n",
        "\n",
        "            d_lossF, _ = dis.train_on_batch(X_fake, y_fake)\n",
        "\n",
        "            X_gan = generate_latent_points(latent_dim, batch_size)\n",
        "\n",
        "            y_gan = ones((batch_size, 1))\n",
        "\n",
        "            gan_loss = gan.train_on_batch(X_gan, y_gan)\n",
        "\n",
        "            print(f'{i}/{n_epochs} - {j}/{batch_p_epoch} - D_lossR : {d_lossR:.2f} - D_lossF : {d_lossF:.2f} - GAN_loss : {gan_loss:.2f}')\n",
        "\n",
        "            if (i+1) % 10 == 0:\n",
        "                # need a view_performance() here"
      ],
      "metadata": {
        "id": "F89Mp5YXajUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' In Sha Allah\n",
        "    will continue with view_performance() tomorrow\n",
        "'''"
      ],
      "metadata": {
        "id": "BqDT4FvDmkXR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
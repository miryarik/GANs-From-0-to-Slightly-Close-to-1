{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn2pTBhHTZMuadv7NFMY+m"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *The original DCGAN paper recommends some practices for stable training process.*\n",
        "A variation of those is given below."
      ],
      "metadata": {
        "id": "P-dJRAXo_c2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "CqiXcffEk2IL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4wagREy_X92"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "   1    Downsample using strided convolutions instead of pooling in the generator.\n",
        "        A stride of (2,2) has the effect of reducing each dimension of the image by half,\n",
        "        effectly resultuing in a feature-man of a quarter size.\n",
        "\n",
        "        for instance, lets say the inputs are colored (3 channel) images, each of size 64 x 64\n",
        "        a conv2d layer of with a (2,2) stride will output an image of 32 x 32 for each of the filters\n",
        "\n",
        "        note that the formula for each output dim is : Output dim_i = ((Input dim_i − Filter dim_ )​ / Strides ) + 1\n",
        "\n",
        "        this means that for a height and width of 64, with the 3,3 kernel size, both height and weight are :\n",
        "\n",
        "        ((64 - 3) / 2 ) + 1 = 61/2 + 1 = 30.5 + 1 = 31.5\n",
        "\n",
        "        the padding = \"same\" parameter will for this to be rounded up (instead of the default of rounding down)\n",
        "        to give an output with dims (32, 32, no. of filters)\n",
        "'''\n",
        "\n",
        "from keras.layers import Conv2D\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3,3), strides = (2,2), padding = \"same\", input_shape = (64, 64, 3)))\n",
        "model.summary()\n",
        "\n",
        "del(model) # so that i can run this cell multiple times without adding more layers to the same model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    2   Upsampling using strided transpose convolutions instead of UpSampling layers in the generator.\n",
        "        A stride of (2,2), which works as output stride for this layer, has the effect of upsampling the\n",
        "        dimensions - in fact doubling them when used with padding = \"same\".\n",
        "\n",
        "        an input of (64,64,3) then produces the output of (128, 128, no. of filters)\n",
        "\n",
        "        recall how upsampling actually works and note that the filters are used to output a smaller matrix for conv2d\n",
        "        while the filters are used to output a smaller matrix for the conv2dtranspose\n",
        "'''\n",
        "\n",
        "from keras.layers import Conv2DTranspose\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2DTranspose(64, (4,4), strides = (2,2), padding = \"same\", input_shape = (64, 63, 3)))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "del(model)"
      ],
      "metadata": {
        "id": "UjgJPTjAAooW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "3   Use leakyReLU instead of relu.\n",
        "    leakyReLU can be used in place of relu in both the G (generator) and the D (discriminator)\n",
        "\n",
        "    the negative_slope for this activation can be specified as an optional parameter\n",
        "    recommended value is 0.2, the default is 0.2\n",
        "\n",
        "    note that the example below used a conv2d, so its for the discriminator.\n",
        "    and the leakyReLU activation causes an output of (32, 32, no. of filters)\n",
        "\n",
        "    leakyReLU, because of the leaky part, accepts some input below the cut-off, unlike relu\n",
        "    this helps in avoiding getting stuck, helping in the training\n",
        "'''\n",
        "\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3,3), strides = (2,2), padding = \"same\", input_shape = (64,64,3)))\n",
        "model.add(LeakyReLU(0.3))\n",
        "\n",
        "model.summary()\n",
        "del(model)"
      ],
      "metadata": {
        "id": "IWNSFAOEh8F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "4   Use batch normalization to standardize the activation outputs from the previous layers\n",
        "    to have a 0 mean and 1 standard deviation, before passing it to the next layer\n",
        "\n",
        "    this can be applied to both G and D\n",
        "\n",
        "    for D, this means sandwiching a batch normalization layer between\n",
        "    the conv2d downsampler and the leakyrelu activation\n",
        "\n",
        "    the values of 0 mean and 1 S.D are defaults. check keras documentation for clarity.\n",
        "'''\n",
        "\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3,3), strides = (2,2), padding = \"same\", input_shape = (64,64,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(0.3))\n",
        "\n",
        "model.summary()\n",
        "del(model)"
      ],
      "metadata": {
        "id": "lXbA96nQl3vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "5   Use a Random 0-centered Gaussian distribution for initialising the weights\n",
        "    a random normal bell-shaped distribution of mean 0 and SD = 0.02 is recommended\n",
        "\n",
        "    this can also be done for both G and D. The example shows for G\n",
        "\n",
        "    these weight initialisers can be used for each layer\n",
        "\n",
        "    for the RandomNormal initializer, mean = 0, stddev = 0.05 are defaults.\n",
        "\n",
        "    the initializer can be specified as an argument in the layers. check keras docs for clarity.\n",
        "'''\n",
        "\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "rand_gaussian = RandomNormal(mean = 0, stddev = 0.02)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2DTranspose(64, (3,3), strides = (2,2), padding = \"same\", input_shape = (64,64,3), kernel_initializer = rand_gaussian))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(0.3))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "del(model)"
      ],
      "metadata": {
        "id": "ayPpLFgMqJ7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "6   Using Adam to optimise the weights by SGD\n",
        "    with the recommended learning_rate and beta_1 momentum as:\n",
        "        learning_rate = 0.0002 (defualt = 0.001)\n",
        "        beta_1 = 0.5 (default = 0.9)\n",
        "\n",
        "    this is done for both models, G and D\n",
        "\n",
        "    note that the model can be saved as an h5 after compilation,\n",
        "    this is useful as it is saved with the specified optimizer\n",
        "    and can be loaded later\n",
        "\n",
        "    note that the loss used is binary_crossentropy, that is for a binary classifier,\n",
        "    and rightly so since the conv2d is used by the discriminiator.\n",
        "'''\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(64, (3,3), strides = (2,2), padding = \"same\", input_shape = (64,64,3))\n",
        "])\n",
        "\n",
        "opt = Adam(lr = 0.0002, beta_1 = 0.5)\n",
        "model.compile(loss = \"binary_crossentropy\", optimizer = opt, metrics = ['accuracy'])\n",
        "\n",
        "del(model)"
      ],
      "metadata": {
        "id": "kNJ1LO_hvi7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "7   Use the hyperbolic tangent activation function as the output from the generator model.\n",
        "    it is also recommended that real images used to train the discriminator\n",
        "    are scaled so that their pixel values are in the range [-1,1].\n",
        "\n",
        "    This is so that the discriminator will always receive images as input, real and fake,\n",
        "    that have pixel values in the same range.\n",
        "\n",
        "    Typically, image data is loaded as a NumPy array such that pixel values are 8-bit unsigned\n",
        "    integers in the range [0, 255].\n",
        "    First, the array must be converted to floating point values, then rescaled to the required range.\n",
        "'''\n",
        "\n",
        "from numpy.random import randint\n",
        "\n",
        "# scale imgs to [-1, 1]\n",
        "def scale_imgs(imgs):\n",
        "    imgs = imgs.astype('float32')     # unit8 to float32\n",
        "    imgs = (imgs - 127.5) / 127.5     # normalize pixel values between -1 and 1\n",
        "    return imgs\n",
        "\n",
        "# define one color img of size 28 x 28\n",
        "imgs = randint(0, 256, 28*28*3) # a 28,28,3 img can be flattened as a 1d vector of size 28*28*3, with values between 0 and 256 (exclusive)\n",
        "imgs = imgs.reshape((1,28,28,3)) # one img\n",
        "\n",
        "print(imgs.min(), imgs.max())\n",
        "scaled = scale_imgs(imgs)\n",
        "\n",
        "print(scaled.min(), scaled.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwYlNM4jzTZ_",
        "outputId": "80e7950c-d5b1-46f6-8af7-d317fbf9380d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 255\n",
            "-1.0 1.0\n"
          ]
        }
      ]
    }
  ]
}
